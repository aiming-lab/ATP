defaults:
  - train: grpo
  - reward: atp_ma
  - dataset: atp_ma_llm
  - _self_

run-name: atp-ma-llm-grpo-qwen3-8B
cuda_visible_devices: '0,1,2,3,4,5,6,7'
model_id: "Qwen/Qwen3-8B" # or "meta-llama/Meta-Llama-3.1-8B-Instruct"

train:
  run_name: ${run-name}
  output_dir: training_output/${run-name}
  logging_steps: 1
  max_prompt_length: 1024
  report_to: wandb
  wandb_name: ${train.run_name}
  wandb_project: ATP
  save_steps: 50
  num_generations: 4
  bf16: True
  attn_implementation: flash_attention_2 # comment this line if not using flash attention
  max_completion_length: 2048
  num_train_epochs: 6.0
  learning_rate: 5e-06
  gradient_accumulation_steps: 4
  deepspeed: config/deepspeed/zero3.json # comment this line if not using deepspeed